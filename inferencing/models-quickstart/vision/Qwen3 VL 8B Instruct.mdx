---
title: 'Qwen3 VL 8B Instruct'
description: '> A vision-language instruction-tuned model for multimodal understanding, OCR, and visual reasoning'
---
<Frame>
  <img src="/images/qwen-vl-abhiiiman.png" />
</Frame>

## About the Provider
Qwen is an AI model family developed by Alibaba Group, a major Chinese technology and cloud computing company. Through its Qwen initiative, Alibaba builds and open-sources advanced language, images and coding models under permissive licenses to support innovation, developer tooling, and scalable AI integration across applications.

## Model Quickstart

This section helps you quickly get started with the `Qwen/Qwen3-VL-8B-Instruct` model on the Qubrid AI inferencing platform.

To use this model, you need:

- A valid **Qubrid API key**
- Access to the Qubrid inference API
- Basic knowledge of making API requests in your preferred language

Once authenticated with your API key, you can send inference requests to the `Qwen/Qwen3-VL-8B-Instruct` model and receive responses based on your input prompts.

Below are example placeholders showing how the model can be accessed using different programming environments.  
You can choose the one that best fits your workflow.

<CodeGroup>
  ```python Python theme={null}
from openai import OpenAI

# Initialize the OpenAI client with Qubrid base URL
client = OpenAI(
    base_url="https://platform.qubrid.com/v1",
    api_key="QUBRID_API_KEY",
)

# Create a streaming chat completion
stream = client.chat.completions.create(
    model="Qwen/Qwen3-VL-8B-Instruct",
    messages=[
      {
        "role": "user",
        "content": [
          {
            "type": "text",
            "text": "What is in this image? Describe the main elements."
          },
          {
            "type": "image_url",
            "image_url": {
              "url": "https://cdn.britannica.com/61/93061-050-99147DCE/Statue-of-Liberty-Island-New-York-Bay.jpg"
            }
          }
        ]
      }
    ],
    max_tokens=2048,
    temperature=0.7,
    top_p=0.9,
    stream=True,
    presence_penalty=0
)

# If stream = False comment this out
for chunk in stream:
    if chunk.choices and chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="", flush=True)
print("\n")

# If stream = True comment this out
print(stream.choices[0].message.content)

```

```js JavaScript theme={null}
import OpenAI from 'openai';

// Initialize the OpenAI client with Qubrid base URL
const client = new OpenAI({
  baseURL: 'https://platform.qubrid.com/v1',
  apiKey: 'QUBRID_API_KEY',
});

// Create a streaming chat completion
const stream = await client.chat.completions.create({
  model: 'Qwen/Qwen3-VL-8B-Instruct',
  messages: [
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "What is in this image? Describe the main elements."
        },
        {
          "type": "image_url",
          "image_url": {
            "url": "https://cdn.britannica.com/61/93061-050-99147DCE/Statue-of-Liberty-Island-New-York-Bay.jpg"
          }
        }
      ]
    }
  ],
  max_tokens: 2048,
  temperature: 0.7,
  top_p: 0.9,
  stream: true,
  presence_penalty: 0
});

// If stream = false comment this out
for await (const chunk of stream) {
  if (chunk.choices[0]?.delta?.content) {
    process.stdout.write(chunk.choices[0].delta.content);
  }
}
console.log('\n');

// If stream = true comment this out
console.log(stream.choices[0].message.content);
```

```go Go theme={null}
package main

import (
	"bufio"
	"bytes"
	"encoding/json"
	"fmt"
	"net/http"
)

func main() {
	url := "https://platform.qubrid.com/v1/chat/completions"

	data := map[string]interface{}{
		"model": "Qwen/Qwen3-VL-8B-Instruct",
		"messages": []map[string]interface{}{
			{
				"role": "user",
				"content": []map[string]interface{}{
					{
						"type": "text",
						"text": "What is in this image? Describe the main elements.",
					},
					{
						"type": "image_url",
						"image_url": map[string]string{
							"url": "https://cdn.britannica.com/61/93061-050-99147DCE/Statue-of-Liberty-Island-New-York-Bay.jpg",
						},
					},
				},
			},
		},
		"max_tokens":       2048,
		"temperature":      0.7,
		"stream":           true,
		"top_p":            0.9,
		"presence_penalty": 0,
	}

	jsonData, _ := json.Marshal(data)
	req, _ := http.NewRequest("POST", url, bytes.NewBuffer(jsonData))
	req.Header.Set("Authorization", "Bearer QUBRID_API_KEY")
	req.Header.Set("Content-Type", "application/json")

	client := &http.Client{}
	res, _ := client.Do(req)
	defer res.Body.Close()

	scanner := bufio.NewScanner(res.Body)
	for scanner.Scan() {
		line := scanner.Text()
		if line != "" {
			fmt.Println(line)
		}
	}
}
```

```curl cURL theme={null}
curl -X POST "https://platform.qubrid.com/v1/chat/completions" \
  -H "Authorization: Bearer QUBRID_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
  "model": "Qwen/Qwen3-VL-8B-Instruct",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "What is in this image? Describe the main elements."
        },
        {
          "type": "image_url",
          "image_url": {
            "url": "https://cdn.britannica.com/61/93061-050-99147DCE/Statue-of-Liberty-Island-New-York-Bay.jpg"
          }
        }
      ]
    }
  ],
  "max_tokens": 2048,
  "temperature": 0.7,
  "stream": true,
  "top_p": 0.9,
  "presence_penalty": 0
}'
```

</CodeGroup>

This will produce a response similar to the one below:

```plain theme={null}
This image captures a classic and iconic view of New York City, featuring several key elements:

- **The Statue of Liberty:** Dominating the left side of the frame, the statue stands tall on Liberty Island, 
  its green patina clearly visible. She is depicted holding her torch aloft and a tablet in her other hand.

- **The New York City Skyline:** In the background, the dense and towering skyline of Manhattan stretches 
  across the horizon. Several famous skyscrapers are identifiable, including the Empire State Building 
  (with its distinctive spire) and the modern glass-and-steel towers of the Financial District.

- **The Water:** A wide expanse of the Hudson River or Upper Bay separates Liberty Island from the city. 
  The water is calm, with gentle ripples, and a few small boats or buoys can be seen.

- **The Setting:** The photograph appears to be taken during the "golden hour" – either sunrise or sunset – 
  as indicated by the warm, soft light bathing the buildings and creating a serene atmosphere.

Overall, the image presents a powerful and recognizable symbol of freedom and welcome set against the 
backdrop of one of the world's most famous and bustling metropolises.
```

## Model Overview

**Qwen3 VL 8B Instruct** is a vision-language instruction-tuned model designed to understand and reason over both text and images. It supports OCR, streaming responses, and rich multimodal conversations, making it suitable for vision-language inference workflows that require text–image understanding rather than content generation. The model focuses on strong visual perception, spatial reasoning, long-context understanding, and multimodal reasoning while remaining accessible for deployment across different environments.

---

## Model at a Glance

| Feature              | Details                                                                 |
|----------------------|-------------------------------------------------------------------------|
| Model ID             | Qwen/Qwen3-VL-8B-Instruct                                                   |
| Provider             | Alibaba Cloud (QwenLM)                                                   |
| Model Type           | Vision-Language Instruction-Tuned Model                                 |
| Architecture         | Transformer decoder-only (Qwen3-VL with ViT visual encoder)                                                                                          |
| Model Size           | 9B                                                                       |
| Parameters           | 6                                                                       |
| Context Length       | 32K tokens                                                               |
| Training Data        | Multilingual multimodal dataset (text + images)                          |
                                                                   
---

## When to use?

Use **Qwen3 VL 8B. Instruct** if your inference workload requires:
- Understanding and reasoning over images and text together
- OCR across multiple languages with structured document understanding
- Visual question answering and image captioning
- Multimodal chat with streaming support
- Spatial reasoning and visual perception without image generation needs

---

### Inference Parameters
| Parameter Name   | Type    | Default | Description                                   |
|------------------|---------|---------|-----------------------------------------------|
| Streaming        | boolean | true    | Enable streaming responses for real-time output. |
| Temperature      | number  | 0.7     | Controls randomness in the output.            |
| Max Tokens       | number  | 2048    | Maximum number of tokens to generate.         |
| Top P            | number  | 0.9     | Controls nucleus sampling.                    |
| Top K            | number  | 50      | Limits sampling to the top-k tokens.          |
| Presence Penalty | number  | 0       | Discourages repeated tokens in the output.    |


## Key Features

- **Strong Vision-Language Capabilities**: Handles text and image understanding in a unified manner  
- **Multilingual OCR**: Supports OCR in up to 32 languages with improved robustness  
- **Long-Context & Video Understanding**: Designed for extended context reasoning within the Qwen3-VL family  
- **Streaming Support**: Enables fast, incremental response generation  
- **Advanced Spatial & Visual Reasoning**: Understands object positions, layouts, and visual relationships  

---

## Summary

**Qwen3 VL 8B Instruct** is a vision-language inference model focused on understanding, reasoning, and interaction across text and images. It supports OCR, streaming responses, and multimodal conversations with strong visual perception and spatial reasoning. The model is suited for document analysis, visual QA, and multimodal chat scenarios. It does not perform image generation and is optimized for understanding tasks. Its Apache 2.0 license and instruction-tuned design make it suitable for accessible deployment on inference platforms.

