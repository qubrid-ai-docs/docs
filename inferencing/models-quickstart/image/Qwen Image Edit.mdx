---
title: 'Qwen Image Edit'
description: '> A 20B multimodal diffusion model for precise, text-guided image editing with strong control over both visual semantics and appearance.'
---

<Frame>
  <img src="/images/qwen-image-edit-abhiiiman.png" />
</Frame>

## About the Provider
Qwen is an AI model family developed by Alibaba Group, a major Chinese technology and cloud computing company. Through its Qwen initiative, Alibaba builds and open-sources advanced language, image and coding models under permissive licenses to support innovation, developer tooling, and scalable AI integration across applications.

# Model Quickstart

This section helps you quickly get started with the `Qwen/Qwen-Image-Edit` model on the Qubrid AI inferencing platform.

To use this model, you need:

- A valid **Qubrid API key**
- Access to the Qubrid inference API
- Basic knowledge of making API requests in your preferred language

Once authenticated with your API key, you can send inference requests to the `Qwen/Qwen-Image-Edit` model and receive responses based on your input prompts.

Below are example placeholders showing how the model can be accessed using different programming environments.  
You can choose the one that best fits your workflow.

<CodeGroup>
```py Python theme={null}
import requests
import base64

url = "https://platform.qubrid.com/api/v1/qubridai/image/edit"

headers = {
    "Authorization": "Bearer <QUBRID_API_KEY>"
}
payload = {
    "model": "Qwen/Qwen-Image-Edit",
    "prompt": "Add a rainbow over the mountains",
    "negative_prompt": "",
    "true_cfg_scale": 4,
    "num_inference_steps": 25,
    "seed": 50,
    "use_inpainting": "false"
}
files = {
    "image": open("image.png", "rb")
}
response = requests.post(
    url,
    headers=headers,
    data=payload,
    files=files
)
if response.status_code != 200:
    print(f"Error {response.status_code}: {response.text}")
    exit(1)
result = response.json()
image_base64 = result["edited_image"]
image_base64 = image_base64.split(",")[-1]
image_bytes = base64.b64decode(image_base64)
with open("edited_image.png", "wb") as f:
    f.write(image_bytes)
print("Image saved to edited_image.png")
```

```js JavaScript theme={null}
import fs from "fs";
const url = "https://platform.qubrid.com/api/v1/qubridai/image/edit";
const form = new FormData();
form.append("model", "Qwen/Qwen-Image-Edit");
form.append("prompt", "Add a rainbow over the mountains");
form.append("negative_prompt", "");
form.append("true_cfg_scale", "4");
form.append("num_inference_steps", "25");
form.append("seed", "50");
form.append("use_inpainting", "false");
form.append(
  "image",
  new Blob([fs.readFileSync("image1.png")], { type: "image/png" }),
  "image1.png"
);
const res = await fetch(url, {
  method: "POST",
  headers: {
    Authorization:
      "Bearer QUBRID_API_KEY",
  },
  body: form,
});
if (!res.ok) {
  const err = await res.text();
  throw new Error(`API error ${res.status}: ${err}`);
}
const result = await res.json();
let base64Image = result.edited_image;
base64Image = base64Image.split(",").pop();
const imageBuffer = Buffer.from(base64Image, "base64");
fs.writeFileSync("edited_image.png", imageBuffer);
console.log("Image saved to edited_image.png");
```

```go Go theme={null}
package main

import (
	"bytes"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"mime/multipart"
	"net/http"
	"os"
)

func main() {
	url := "https://platform.qubrid.com/api/v1/qubridai/image/edit"

	body := &bytes.Buffer{}
	writer := multipart.NewWriter(body)
	writer.WriteField("model", "Qwen/Qwen-Image-Edit")
	writer.WriteField("prompt", "Add a rainbow over the mountains")
	writer.WriteField("negative_prompt", "")
	writer.WriteField("true_cfg_scale", "4")
	writer.WriteField("num_inference_steps", "25")
	writer.WriteField("seed", "50")
	writer.WriteField("use_inpainting", "false")

	file, err := os.Open("image1.png")
	if err != nil {
		log.Fatal(err)
	}
	defer file.Close()
	part, err := writer.CreateFormFile("image", "image1.png")
	if err != nil {
		log.Fatal(err)
	}
	_, err = io.Copy(part, file)
	if err != nil {
		log.Fatal(err)
	}
	writer.Close()
	req, err := http.NewRequest("POST", url, body)
	if err != nil {
		log.Fatal(err)
	}
	req.Header.Set(
		"Authorization",
		"Bearer <QUBRID_API_KEY>",
	)
	req.Header.Set("Content-Type", writer.FormDataContentType())
	client := &http.Client{}
	res, err := client.Do(req)
	if err != nil {
		log.Fatal(err)
	}
	defer res.Body.Close()
	if res.StatusCode != http.StatusOK {
		errBody, _ := io.ReadAll(res.Body)
		log.Fatalf("API error %d: %s", res.StatusCode, errBody)
	}
	var result map[string]interface{}
	json.NewDecoder(res.Body).Decode(&result)

	base64Image, ok := result["edited_image"].(string)
	if !ok {
		log.Fatal("edited_image not found in response")
	}
	imageBytes, err := base64.StdEncoding.DecodeString(base64Image)
	if err != nil {
		log.Fatal(err)
	}
	os.WriteFile("edited_image.png", imageBytes, 0644)
	fmt.Println("Image saved to edited_image.png")
}
```
```curl cURL theme={null}
curl --location 'https://platform.qubrid.com/api/v1/qubridai/image/edit' \
--header 'Authorization: Bearer <QUBRID-API-KEY>' \
--form 'model="Qwen/Qwen-Image-Edit"' \
--form 'prompt="Add a rainbow over the mountains"' \
--form 'negative_prompt=""' \
--form 'true_cfg_scale="4"' \
--form 'num_inference_steps="25"' \
--form 'seed="50"' \
--form 'use_inpainting="false"' \
--form 'image=@"<YOUR-IMAGE-COMPLETE-PATH>"'
```
</CodeGroup>

### API Generated Response
- Input Image
<Frame>
  <img src="/images/z-image-turbo-demo.png" />
</Frame>
> Edit Prompt: Change the text to "MIDNIGHT DRIVE".
- Output Image
<Frame>
  <img src="/images/Qwen-Image-Edit-Demo.png" />
</Frame>

## Qwen Image Edit

### Model Overview
**Qwen Image Edit** is the image editing version of Qwen-Image, built on top of the 20B Qwen-Image model.  
- It extends Qwen-Image’s text rendering capabilities to image editing tasks, enabling precise text edits directly within images.  
- The model processes the input image through Qwen2.5-VL for visual semantic control and a VAE Encoder for visual appearance control, allowing both semantic-level and appearance-level edits in a single workflow.  
- It supports text-guided image editing while preserving visual fidelity and layout.

---

### Model at a Glance

| Feature | Details |
|------|------|
| Model ID | Qwen/Qwen-Image-Edit |
| Base Model | Qwen-Image |
| Model Type | Multimodal Diffusion Model |
| Architecture | Transformer decoder-only (GPT-NeoX design) |
| Model Size | 20B |
| Parameters | 4  |

---

### When to use?
You should use **Qwen Image Edit** if you need:
- Text-guided image editing with precise control  
- Direct text addition, deletion, or modification in images while preserving original font, size, and style  
- Both low-level appearance edits (with unchanged surrounding regions) and high-level semantic edits  
- Consistent visual quality and layout preservation during edits  

---

### Supported Editing Capabilities
- Low-level visual appearance editing (adding, removing, or modifying elements while keeping other regions unchanged)
- High-level visual semantic editing (object rotation, style transfer, IP creation with semantic consistency)
- Precise bilingual text editing (Chinese and English)
---

### Inference Parameters

| Parameter Name   | Type   | Default | Description                                   |
|------------------|--------|---------|-----------------------------------------------|
| Negative Prompt  | string | —       | Specifies what to exclude from the generation |
| Guidance Scale   | number | 4       | Controls prompt adherence (CFG scale)         |
| Steps            | number | 25      | Number of generation steps                    |
| Seed             | number | 50      | Random seed for reproducibility               |

### Key Features
- **Semantic and Appearance Editing**: Supports both low-level appearance edits (with unchanged surrounding regions) and high-level semantic edits while maintaining semantic consistency.  
- **Precise Text Editing**: Enables direct addition, deletion, and modification of Chinese and English text in images while preserving original font, size, and style.  
- **Dual Visual Control Pipeline**: Uses Qwen2.5-VL for visual semantic control and a VAE Encoder for visual appearance control within the same editing process.  
- **Text-Guided Image Editing**: Performs controlled edits through text instructions while preserving visual fidelity and layout.  
- **Strong Benchmark Performance**: Achieves state-of-the-art performance on multiple public image editing benchmarks.

---

### Summary
**Qwen Image Edit** is a multimodal diffusion model designed for controlled image editing tasks.  
- It extends Qwen-Image’s text rendering strengths to precise image and text edits.  
- The model supports both semantic-level and appearance-level modifications in a single workflow.  
- It enables bilingual text editing directly inside images with high visual consistency.  
- This makes it suitable for inference use cases requiring accurate, layout-preserving image edits.

For a comprehensive overview of `Qwen-Image-Edit`  
visit [Qubrid's Official Medium Guide](https://medium.com/@qubrid/the-ultimate-guide-to-advanced-ai-image-editing-workflow-using-qubrid-ais-comfyui-template-a1bd14e450b3).

